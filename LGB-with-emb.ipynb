{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_path = Path(\"part-2\")\n",
    "part_path.mkdir(exist_ok=True)\n",
    "\n",
    "raw_path = Path(f\"{part_path}/raw\")\n",
    "raw_path.mkdir(exist_ok=True)\n",
    "\n",
    "processed_path = Path(f\"{part_path}/processed\")\n",
    "processed_path.mkdir(exist_ok=True)\n",
    "\n",
    "submission_path = Path(f\"{part_path}/submission\")\n",
    "submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f\"{processed_path}/train-weighted.csv\")\n",
    "df_test = pd.read_csv(f\"{processed_path}/test-weighted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_embs = pd.read_csv(f\"{processed_path}/train-embeddings-only.csv\")\n",
    "df_test_embs = pd.read_csv(f\"{processed_path}/test-embeddings-only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>project_a</th>\n",
       "      <th>project_b</th>\n",
       "      <th>weight_a</th>\n",
       "      <th>weight_b</th>\n",
       "      <th>total_amount_usd</th>\n",
       "      <th>funder</th>\n",
       "      <th>quarter</th>\n",
       "      <th>overview</th>\n",
       "      <th>embedding</th>\n",
       "      <th>overview_b</th>\n",
       "      <th>embedding_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20953</th>\n",
       "      <td>20879</td>\n",
       "      <td>https://github.com/pytest-dev/pytest</td>\n",
       "      <td>https://github.com/import-js/eslint-plugin-import</td>\n",
       "      <td>0.923832</td>\n",
       "      <td>0.076168</td>\n",
       "      <td>5908</td>\n",
       "      <td>opencollective</td>\n",
       "      <td>2023-10</td>\n",
       "      <td>### Overview of Pytest\\n\\n**1. By Function or ...</td>\n",
       "      <td>[0.010156410746276379, -0.03437905013561249, 0...</td>\n",
       "      <td>### Overview of `eslint-plugin-import`\\n\\n**1....</td>\n",
       "      <td>[-0.008927255868911743, 0.021994858980178833, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20954</th>\n",
       "      <td>20880</td>\n",
       "      <td>https://github.com/pytest-dev/pytest</td>\n",
       "      <td>https://github.com/webreflection/flatted</td>\n",
       "      <td>0.884746</td>\n",
       "      <td>0.115254</td>\n",
       "      <td>6169</td>\n",
       "      <td>opencollective</td>\n",
       "      <td>2023-10</td>\n",
       "      <td>### Overview of Pytest\\n\\n**1. By Function or ...</td>\n",
       "      <td>[0.010156410746276379, -0.03437905013561249, 0...</td>\n",
       "      <td>**Overview of the Project: Flatted**\\n\\n### 1....</td>\n",
       "      <td>[-0.02596249058842659, 0.006722309160977602, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20955</th>\n",
       "      <td>20881</td>\n",
       "      <td>https://github.com/clap-rs/clap</td>\n",
       "      <td>https://github.com/import-js/eslint-plugin-import</td>\n",
       "      <td>0.554455</td>\n",
       "      <td>0.445545</td>\n",
       "      <td>1010</td>\n",
       "      <td>opencollective</td>\n",
       "      <td>2023-10</td>\n",
       "      <td>Certainly! Here’s an overview of the `clap` pr...</td>\n",
       "      <td>[-0.03318300470709801, 0.026065200567245483, -...</td>\n",
       "      <td>### Overview of `eslint-plugin-import`\\n\\n**1....</td>\n",
       "      <td>[-0.008927255868911743, 0.021994858980178833, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20956</th>\n",
       "      <td>20882</td>\n",
       "      <td>https://github.com/clap-rs/clap</td>\n",
       "      <td>https://github.com/webreflection/flatted</td>\n",
       "      <td>0.440598</td>\n",
       "      <td>0.559402</td>\n",
       "      <td>1271</td>\n",
       "      <td>opencollective</td>\n",
       "      <td>2023-10</td>\n",
       "      <td>Certainly! Here’s an overview of the `clap` pr...</td>\n",
       "      <td>[-0.03318300470709801, 0.026065200567245483, -...</td>\n",
       "      <td>**Overview of the Project: Flatted**\\n\\n### 1....</td>\n",
       "      <td>[-0.02596249058842659, 0.006722309160977602, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20957</th>\n",
       "      <td>20883</td>\n",
       "      <td>https://github.com/import-js/eslint-plugin-import</td>\n",
       "      <td>https://github.com/webreflection/flatted</td>\n",
       "      <td>0.387597</td>\n",
       "      <td>0.612403</td>\n",
       "      <td>1161</td>\n",
       "      <td>opencollective</td>\n",
       "      <td>2023-10</td>\n",
       "      <td>### Overview of `eslint-plugin-import`\\n\\n**1....</td>\n",
       "      <td>[-0.008927255868911743, 0.021994858980178833, ...</td>\n",
       "      <td>**Overview of the Project: Flatted**\\n\\n### 1....</td>\n",
       "      <td>[-0.02596249058842659, 0.006722309160977602, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                          project_a  \\\n",
       "20953  20879               https://github.com/pytest-dev/pytest   \n",
       "20954  20880               https://github.com/pytest-dev/pytest   \n",
       "20955  20881                    https://github.com/clap-rs/clap   \n",
       "20956  20882                    https://github.com/clap-rs/clap   \n",
       "20957  20883  https://github.com/import-js/eslint-plugin-import   \n",
       "\n",
       "                                               project_b  weight_a  weight_b  \\\n",
       "20953  https://github.com/import-js/eslint-plugin-import  0.923832  0.076168   \n",
       "20954           https://github.com/webreflection/flatted  0.884746  0.115254   \n",
       "20955  https://github.com/import-js/eslint-plugin-import  0.554455  0.445545   \n",
       "20956           https://github.com/webreflection/flatted  0.440598  0.559402   \n",
       "20957           https://github.com/webreflection/flatted  0.387597  0.612403   \n",
       "\n",
       "       total_amount_usd          funder  quarter  \\\n",
       "20953              5908  opencollective  2023-10   \n",
       "20954              6169  opencollective  2023-10   \n",
       "20955              1010  opencollective  2023-10   \n",
       "20956              1271  opencollective  2023-10   \n",
       "20957              1161  opencollective  2023-10   \n",
       "\n",
       "                                                overview  \\\n",
       "20953  ### Overview of Pytest\\n\\n**1. By Function or ...   \n",
       "20954  ### Overview of Pytest\\n\\n**1. By Function or ...   \n",
       "20955  Certainly! Here’s an overview of the `clap` pr...   \n",
       "20956  Certainly! Here’s an overview of the `clap` pr...   \n",
       "20957  ### Overview of `eslint-plugin-import`\\n\\n**1....   \n",
       "\n",
       "                                               embedding  \\\n",
       "20953  [0.010156410746276379, -0.03437905013561249, 0...   \n",
       "20954  [0.010156410746276379, -0.03437905013561249, 0...   \n",
       "20955  [-0.03318300470709801, 0.026065200567245483, -...   \n",
       "20956  [-0.03318300470709801, 0.026065200567245483, -...   \n",
       "20957  [-0.008927255868911743, 0.021994858980178833, ...   \n",
       "\n",
       "                                              overview_b  \\\n",
       "20953  ### Overview of `eslint-plugin-import`\\n\\n**1....   \n",
       "20954  **Overview of the Project: Flatted**\\n\\n### 1....   \n",
       "20955  ### Overview of `eslint-plugin-import`\\n\\n**1....   \n",
       "20956  **Overview of the Project: Flatted**\\n\\n### 1....   \n",
       "20957  **Overview of the Project: Flatted**\\n\\n### 1....   \n",
       "\n",
       "                                             embedding_b  \n",
       "20953  [-0.008927255868911743, 0.021994858980178833, ...  \n",
       "20954  [-0.02596249058842659, 0.006722309160977602, -...  \n",
       "20955  [-0.008927255868911743, 0.021994858980178833, ...  \n",
       "20956  [-0.02596249058842659, 0.006722309160977602, -...  \n",
       "20957  [-0.02596249058842659, 0.006722309160977602, -...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_embs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "def normalize_l2(x):\n",
    "    x = np.array(x)\n",
    "    if x.ndim == 1:\n",
    "        norm = np.linalg.norm(x)\n",
    "        if norm == 0:\n",
    "            return x\n",
    "        return x / norm\n",
    "    else:\n",
    "        norm = np.linalg.norm(x, 2, axis=1, keepdims=True)\n",
    "        return np.where(norm == 0, x, x / norm)\n",
    "    \n",
    "def process_embeddings(embedding_series):\n",
    "    return np.array([normalize_l2(literal_eval(emb)[:128]) for emb in embedding_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_a = process_embeddings(df_train_embs.embedding)\n",
    "train_embeddings_b = process_embeddings(df_train_embs.embedding_b)\n",
    "train_features = np.hstack([\n",
    "    train_embeddings_a,\n",
    "    train_embeddings_b\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings_a = process_embeddings(df_test_embs.embedding)\n",
    "test_embeddings_b = process_embeddings(df_test_embs.embedding_b)\n",
    "test_features = np.hstack([\n",
    "    test_embeddings_a,\n",
    "    test_embeddings_b\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f'{processed_path}/arrays.npz', train_features=train_features, test_features=test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load(f'{processed_path}/arrays.npz')\n",
    "train_features = loaded['train_features']\n",
    "test_features = loaded['test_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "   \"size\", \n",
    "   \"size_b\", \n",
    "   \"size_ratio\",\n",
    "   \"stars\", \n",
    "   \"stars_b\", \n",
    "   \"stars_ratio\",\n",
    "   \"watchers\",\n",
    "   \"watchers_b\",\n",
    "   \"watchers_ratio\",\n",
    "   \"forks\", \n",
    "   \"forks_b\", \n",
    "   \"forks_ratio\", \n",
    "   \"open_issues\", \n",
    "   \"open_issues_b\", \n",
    "   \"issues_ratio\",\n",
    "   \"subscribers_count\", \n",
    "   \"subscribers_count_b\",  \n",
    "   \"subscribers_ratio\",\n",
    "   \"commit_code\",\n",
    "   \"commit_code_b\",\n",
    "   \"commits_ratio\",\n",
    "   \"forked\",\n",
    "   \"forked_b\",\n",
    "   \"forked_ratio\",\n",
    "   \"issue_closed\",\n",
    "   \"issue_closed_b\",\n",
    "   \"issue_closed_ratio\",\n",
    "   \"issue_comment\",\n",
    "   \"issue_comment_b\",\n",
    "   \"issue_comment_ratio\",\n",
    "   \"issue_opened\",\n",
    "   \"issue_opened_b\",\n",
    "   \"issue_opened_ratio\",\n",
    "   \"issue_reopened\",\n",
    "   \"issue_reopened_b\",\n",
    "   \"issue_reopened_ratio\",\n",
    "   \"pull_request_closed\",\n",
    "   \"pull_request_closed_b\",\n",
    "   \"pull_request_closed_ratio\",\n",
    "   \"pull_request_merged\",\n",
    "   \"pull_request_merged_b\",\n",
    "   \"pull_request_merged_ratio\",\n",
    "   \"pull_request_opened\",\n",
    "   \"pull_request_opened_b\",\n",
    "   \"pull_request_opened_ratio\",\n",
    "   \"pull_request_reopened\",\n",
    "   \"pull_request_reopened_b\",\n",
    "   \"pull_request_reopened_ratio\",\n",
    "   \"pull_request_review_comment\",\n",
    "   \"pull_request_review_comment_b\",\n",
    "   \"pull_request_review_comment_ratio\",\n",
    "   \"release_published\",\n",
    "   \"release_published_b\",\n",
    "   \"release_published_ratio\",\n",
    "   \"starred\",\n",
    "   \"starred_b\",\n",
    "   \"starred_ratio\",\n",
    "   \"v_index\",\n",
    "   \"v_index_b\",\n",
    "   \"v_index_ratio\",\n",
    "   \"stars_intersection_v_index\",\n",
    "   \"stars_b_intersection_v_index_b\",\n",
    "   \"stars_ratio_intersection_v_index_ratio\",\n",
    "   \"num_dependents\",\n",
    "   \"num_dependents_b\",\n",
    "   \"dependency_rank\",\n",
    "   \"dependency_rank_b\",\n",
    "   \"num_dependents_ratio\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.hstack([\n",
    "    train_features,\n",
    "    df_train[features].to_numpy()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.hstack([\n",
    "    test_features,\n",
    "    df_test[features].to_numpy()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_features\n",
    "y = df_train[\"weight_a\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 43072\n",
      "[LightGBM] [Info] Number of data points in the train set: 16766, number of used features: 324\n",
      "[LightGBM] [Info] Start training from score 0.487758\n",
      "[LightGBM] [Info] Total Bins 42940\n",
      "[LightGBM] [Info] Number of data points in the train set: 16766, number of used features: 324\n",
      "[LightGBM] [Info] Start training from score 0.489256\n",
      "[LightGBM] [Info] Total Bins 42922\n",
      "[LightGBM] [Info] Number of data points in the train set: 16766, number of used features: 324\n",
      "[LightGBM] [Info] Start training from score 0.485152\n",
      "[LightGBM] [Info] Total Bins 42934\n",
      "[LightGBM] [Info] Number of data points in the train set: 16767, number of used features: 324\n",
      "[LightGBM] [Info] Start training from score 0.486161\n",
      "[LightGBM] [Info] Total Bins 43071\n",
      "[LightGBM] [Info] Number of data points in the train set: 16767, number of used features: 324\n",
      "[LightGBM] [Info] Start training from score 0.488246\n",
      "Cross-validation MSE: 0.0166 (+/- 0.0002)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "lgb_train_data = lgb.Dataset(X, label=y)\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"mse\",\n",
    "    \"force_col_wise\": True,\n",
    "    \"num_leaves\": 100,\n",
    "    # \"min_data_in_leaf\": 20,  # Helps prevent overfitting\n",
    "    # \"max_bin\": 255,  # Reduces complexity\n",
    "    # \"learning_rate\": 0.01,  # Smaller learning rate for better control\n",
    "    # \"min_gain_to_split\": 0.1,  # Prevents unnecessary splits\n",
    "    # \"lambda_l1\": 0.1,  # L1 regularization\n",
    "    # \"lambda_l2\": 0.1,  # L2 regularization\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    # Create training and validation datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params, \n",
    "        train_data, \n",
    "        valid_sets=[val_data],\n",
    "        # num_boost_round=1000,\n",
    "        # early_stopping_rounds=50,\n",
    "        # verbose_eval=False\n",
    "    )\n",
    "\n",
    "    # Make predictions and calculate MSE\n",
    "    y_pred = model.predict(X_val)\n",
    "    mse = np.mean((y_val - y_pred) ** 2)\n",
    "    cv_scores.append(mse)\n",
    "\n",
    "# Calculate mean and std of MSE scores\n",
    "cv_scores = np.array(cv_scores)\n",
    "mean_mse = cv_scores.mean()\n",
    "std_mse = cv_scores.std()\n",
    "\n",
    "print(f\"Cross-validation MSE: {mean_mse:.4f} (+/- {std_mse:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 43081\n",
      "[LightGBM] [Info] Number of data points in the train set: 20958, number of used features: 324\n",
      "[LightGBM] [Info] Start training from score 0.487315\n"
     ]
    }
   ],
   "source": [
    "# Train model on the entire dataset\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_features\n",
    "\n",
    "lgb_test_data = lgb.Dataset(X_test)\n",
    "\n",
    "test_predictions = model.predict(X_test)\n",
    "test_predictions = pd.Series(test_predictions.tolist()).round(6).clip(0.000001, 0.999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All predictions are < 1\n"
     ]
    }
   ],
   "source": [
    "# Check if any predictions are >= 1\n",
    "if (test_predictions >= 1).any():\n",
    "    print(\"Warning: Found predictions >= 1\")\n",
    "    print(\"Max prediction value:\", test_predictions.max())\n",
    "else:\n",
    "    print(\"All predictions are < 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m importance \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfeature_importance()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create DataFrame in Pandas\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimportance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimportance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Sort by importance in ascending order\u001b[39;00m\n\u001b[1;32m      9\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m feature_importance\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimportance\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/deepfunding/.venv/lib/python3.13/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/deepfunding/.venv/lib/python3.13/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deepfunding/.venv/lib/python3.13/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/deepfunding/.venv/lib/python3.13/site-packages/pandas/core/internals/construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    662\u001b[0m         raw_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importance = model.feature_importance()\n",
    "\n",
    "# Create DataFrame in Pandas\n",
    "feature_importance = pd.DataFrame({\"feature\": test_features, \"importance\": importance.tolist()})\n",
    "\n",
    "# Sort by importance in ascending order\n",
    "feature_importance = feature_importance.sort_values(by=\"importance\", ascending=True)\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(12, 8))  # Adjust width and height as needed\n",
    "\n",
    "# Plot horizontal bar chart\n",
    "feature_importance.plot.barh(x=\"feature\", y=\"importance\", legend=False, figsize=(12, 10))\n",
    "\n",
    "# Improve layout\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: part-2/submission/submission_2025-02-13_19-54-00-mse_0.016770.csv\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "submission_path = Path(f\"{part_path}/submission\")\n",
    "\n",
    "df_submission = df_test[[\"id\"]].copy()  # Select \"id\" column\n",
    "df_submission[\"pred\"] = test_predictions  # Add predictions column\n",
    "\n",
    "# Create filename with timestamp and MSE\n",
    "filename = f\"{submission_path}/submission_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}-mse_{mean_mse:.6f}.csv\"\n",
    "\n",
    "# Save to CSV\n",
    "df_submission.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Saved file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# import lightgbm as lgb\n",
    "\n",
    "# # Define the parameter grid\n",
    "# param_grid = {\n",
    "#     'num_leaves': [31, 50, 100],\n",
    "#     'max_depth': [-1, 5, 10],  # -1 means no limit\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'min_child_samples': [20, 50, 100],\n",
    "#     'subsample': [0.8, 0.9, 1.0],\n",
    "#     'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "#     'reg_alpha': [0, 0.1, 0.5],\n",
    "#     'reg_lambda': [0, 0.1, 0.5]\n",
    "# }\n",
    "# param_grid_small = {\n",
    "#     'num_leaves': [31, 50],\n",
    "#     'learning_rate': [0.01, 0.1],\n",
    "#     'n_estimators': [100, 200],\n",
    "#     'subsample': [0.8, 1.0]\n",
    "# }\n",
    "\n",
    "# # Initialize LightGBM model\n",
    "# lgb_model = lgb.LGBMRegressor(\n",
    "#     objective='regression',\n",
    "#     metric='mse',\n",
    "#     force_col_wise=True,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Initialize GridSearchCV\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=lgb_model,\n",
    "#     param_grid=param_grid_small,\n",
    "#     cv=5,\n",
    "#     scoring='neg_mean_squared_error',\n",
    "#     n_jobs=-1,  # Use all CPU cores\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # Perform grid search\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# # Print results\n",
    "# print(\"\\nBest parameters found:\")\n",
    "# print(grid_search.best_params_)\n",
    "# print(f\"\\nBest MSE: {-grid_search.best_score_:.4f}\")\n",
    "\n",
    "# # Get the best model\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# # Make predictions on test set using best model\n",
    "# X_test = df_test[features].to_numpy()\n",
    "# test_predictions = best_model.predict(X_test)\n",
    "# test_predictions = pd.Series(test_predictions).round(6).clip(0)\n",
    "\n",
    "# # Save feature importance plot for best model\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# feature_importance = pd.DataFrame({\n",
    "#     'feature': features,\n",
    "#     'importance': best_model.feature_importances_\n",
    "# })\n",
    "# feature_importance = feature_importance.sort_values('importance', ascending=True)\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# feature_importance.plot.barh(x='feature', y='importance', legend=False)\n",
    "# plt.xlabel('Importance')\n",
    "# plt.ylabel('Feature')\n",
    "# plt.title('Feature Importance (Best Model)')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
