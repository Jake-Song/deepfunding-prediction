{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "part_path = Path(\"part-2\")\n",
    "part_path.mkdir(exist_ok=True)\n",
    "\n",
    "raw_path = Path(f\"{part_path}/raw\")\n",
    "raw_path.mkdir(exist_ok=True)\n",
    "\n",
    "processed_path = Path(f\"{part_path}/processed\")\n",
    "processed_path.mkdir(exist_ok=True)\n",
    "\n",
    "submission_path = Path(f\"{part_path}/submission\")\n",
    "submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-2/raw\n"
     ]
    }
   ],
   "source": [
    "print(raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with your path to credentials\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '../oso_gcp_credentials.json'\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.getenv('GCP_CREDENTIAL_PATH')\n",
    "# replace with your project name\n",
    "# client = bigquery.Client(project='opensource-observer')\n",
    "client = bigquery.Client(project=os.getenv('GCP_PROJECT_ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_array(arr):\n",
    "    return \"'\" + \"','\".join(arr) + \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_str(projects):\n",
    "    projects = [p.replace('https://github.com/', '') for p in projects]\n",
    "    return projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_str_df(df):\n",
    "    df['project_a'] = df['project_a'].str.replace('https://github.com/', '')\n",
    "    df['project_b'] = df['project_b'].str.replace('https://github.com/', '')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    if str(part_path) == 'part-1':\n",
    "        # repository_url = (\n",
    "        #     \"https://raw.githubusercontent.com/deepfunding/mini-contest/refs/heads/main/\"\n",
    "        # )\n",
    "        \n",
    "        # df_train = pd.read_csv(f\"{repository_url}/dataset.csv\")\n",
    "        # df_test = pd.read_csv(f\"{repository_url}/test.csv\")\n",
    "        # df_train.to_csv(f\"{part_path}/train.csv\", index=False)\n",
    "        # df_test.to_csv(f\"{part_path}/test.csv\", index=False)\n",
    "        df_train = pd.read_csv(f\"{part_path}/train.csv\")\n",
    "        df_test = pd.read_csv(f\"{part_path}/test.csv\")\n",
    "        \n",
    "    elif str(part_path) == 'part-2':\n",
    "        df_train = pd.read_csv(f\"{part_path}/train.csv\")\n",
    "        df_test = pd.read_csv(f\"{part_path}/test.csv\")\n",
    "     \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20958, 4261)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = pd.concat([\n",
    "    df_train['project_a'],\n",
    "    df_train['project_b'],\n",
    "    df_test['project_a'],\n",
    "    df_test['project_b']\n",
    "]).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/mochajs/mocha',\n",
       " 'https://github.com/chzyer/readline',\n",
       " 'https://github.com/gulpjs/gulp',\n",
       " 'https://github.com/webpack/webpack',\n",
       " 'https://github.com/redux-saga/redux-saga']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_data(projects):\n",
    "    headers = {\n",
    "    \"Accept\": \"application/vnd.github+json\",\n",
    "    \"Authorization\": f\"Bearer {os.getenv('GITHUB_TOKEN')}\",\n",
    "    \"X-GitHub-Api-Version\": \"2022-11-28\",\n",
    "    }\n",
    "\n",
    "    data = []\n",
    "    for project in projects:\n",
    "        api_url = f\"https://api.github.com/repos/{project}\"\n",
    "        response = requests.get(api_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data.append(response.json())\n",
    "    df_projects = pd.DataFrame(data)\n",
    "    df_projects.to_csv(f\"{raw_path}/github-projects.csv\", index=False)\n",
    "\n",
    "    return df_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimed_projects = remove_str(projects)\n",
    "df_projects = get_repo_data(trimed_projects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_activity(urls):\n",
    "    \n",
    "    q = f\"\"\"\n",
    "    WITH repos as(\n",
    "    SELECT\n",
    "        artifact_id,\n",
    "        artifact_url AS repo_url,\n",
    "    FROM\n",
    "        `oso_production.repositories_v0`\n",
    "    ),\n",
    "    events as(\n",
    "    SELECT\n",
    "        artifact_id,\n",
    "        event_type,\n",
    "        CAST(sum(amount) AS FLOAT64) AS total_amount\n",
    "    FROM\n",
    "        `oso_production.events_monthly_to_artifact`\n",
    "    WHERE bucket_month >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 180 DAY)\n",
    "    GROUP BY 1,2\n",
    "    )\n",
    "    SELECT\n",
    "        repos.repo_url,\n",
    "        events.event_type,\n",
    "        events.total_amount\n",
    "    FROM repos\n",
    "    JOIN events\n",
    "        ON repos.artifact_id = events.artifact_id\n",
    "    WHERE repo_url IN ({stringify_array(urls)})\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    results = client.query(q)\n",
    "    df = results.to_dataframe()\n",
    "    df_pivot = df.pivot_table(index=['repo_url'], columns='event_type', values='total_amount', fill_value=0)\n",
    "    df_pivot.reset_index(inplace=True)\n",
    "    df_pivot.to_csv(f\"{raw_path}/github-activity.csv\", index=False)\n",
    "    return df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/deepfunding/.venv/lib/python3.13/site-packages/google/cloud/bigquery/table.py:1820: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_act = get_repo_activity(projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 5235\n",
      "Edges: 17367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/deepfunding/.venv/lib/python3.13/site-packages/networkx/readwrite/json_graph/node_link.py:287: FutureWarning: \n",
      "The default value will be changed to `edges=\"edges\" in NetworkX 3.6.\n",
      "\n",
      "To make this warning go away, explicitly set the edges kwarg, e.g.:\n",
      "\n",
      "  nx.node_link_graph(data, edges=\"links\") to preserve current behavior, or\n",
      "  nx.node_link_graph(data, edges=\"edges\") for forward compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open(\"unweighted_graph.json\", 'r') as f:\n",
    "    graph_data = json.load(f)\n",
    "\n",
    "G_original = nx.node_link_graph(graph_data)\n",
    "print(\"Nodes:\", len(G_original.nodes))\n",
    "repo_urls = [x for x in G_original.nodes]\n",
    "print(\"Edges:\", len(G_original.edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_metrics_and_metadata(urls):\n",
    "    query = f\"\"\"\n",
    "    WITH repos AS (\n",
    "    SELECT *\n",
    "    FROM `oso_production.repositories_v0`\n",
    "    ),\n",
    "    package_owners AS (\n",
    "    SELECT\n",
    "        package_owner_artifact_id,\n",
    "        package_artifact_source,\n",
    "        package_artifact_name,\n",
    "        CONCAT(package_artifact_source, '/', package_artifact_name) AS package_tag\n",
    "    FROM `oso_production.package_owners_v0`\n",
    "    WHERE package_owner_artifact_id IN (SELECT artifact_id FROM repos)\n",
    "    ),\n",
    "    oso_dependents AS (\n",
    "    SELECT\n",
    "        package_owners.package_owner_artifact_id,\n",
    "        COUNT(DISTINCT package_owners.package_tag) AS num_packages,\n",
    "        COUNT(DISTINCT sboms.from_artifact_namespace) AS num_dependents_in_oso,\n",
    "        ARRAY_AGG(DISTINCT package_owners.package_tag) AS list_of_packages,\n",
    "        ARRAY_AGG(DISTINCT sboms.from_artifact_namespace) AS list_of_dependents_in_oso\n",
    "    FROM `oso_production.sboms_v0` AS sboms\n",
    "    JOIN package_owners\n",
    "        ON sboms.to_package_artifact_name = package_owners.package_artifact_name\n",
    "        AND sboms.to_package_artifact_source = package_owners.package_artifact_source\n",
    "    GROUP BY 1\n",
    "    ),\n",
    "    grants AS (\n",
    "    SELECT\n",
    "        funding.to_project_id AS project_id,\n",
    "        ARRAY_AGG(DISTINCT projects.display_name) AS list_of_funders,\n",
    "        SUM(funding.amount) AS total_funding_usd,\n",
    "        SUM(CASE WHEN funding.time > '2023-01-01' THEN funding.amount ELSE 0 END) AS total_funding_usd_since_2023\n",
    "    FROM `oso_production.oss_funding_v0` AS funding\n",
    "    JOIN `oso_production.projects_v1` AS projects\n",
    "        ON funding.from_project_id = projects.project_id\n",
    "    WHERE funding.from_project_name IN ('gitcoin', 'octant-golemfoundation', 'opencollective', 'optimism')\n",
    "    GROUP BY 1\n",
    "    ),\n",
    "    combined AS (\n",
    "    SELECT\n",
    "        repos.artifact_url AS repo_url,\n",
    "        repos.artifact_namespace AS maintainer,\n",
    "        repos.language,\n",
    "        repos.is_fork,\n",
    "        DATE(repos.created_at) as created_at,\n",
    "        DATE(repos.updated_at) as updated_at,\n",
    "        repos.star_count,\n",
    "        repos.fork_count,\n",
    "        COALESCE(oso_dependents.num_packages, 0) AS num_packages,\n",
    "        COALESCE(oso_dependents.num_dependents_in_oso, 0) AS num_dependents_in_oso,\n",
    "        oso_dependents.list_of_dependents_in_oso,\n",
    "        oso_dependents.list_of_packages,\n",
    "        grants.list_of_funders,\n",
    "        COALESCE(grants.total_funding_usd, 0) AS total_funding_usd,\n",
    "        COALESCE(grants.total_funding_usd_since_2023, 0) AS total_funding_usd_since_2023\n",
    "    FROM repos\n",
    "    LEFT JOIN oso_dependents\n",
    "        ON repos.artifact_id = oso_dependents.package_owner_artifact_id\n",
    "    LEFT JOIN grants\n",
    "        ON repos.project_id = grants.project_id\n",
    "    )\n",
    "    SELECT\n",
    "    *,\n",
    "    PERCENT_RANK() OVER (ORDER BY num_dependents_in_oso) AS oso_dependency_rank,\n",
    "    COUNT(*) OVER (PARTITION BY language) AS num_repos_in_same_language,\n",
    "    PERCENT_RANK() OVER (PARTITION BY language ORDER BY num_dependents_in_oso) AS oso_dependency_rank_for_language\n",
    "    FROM combined\n",
    "    WHERE repo_url IN ({stringify_array(repo_urls)})\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # execute the query and save it\n",
    "    results = client.query(query)\n",
    "    df = results.to_dataframe()\n",
    "    df.to_csv(f\"{raw_path}/repo_metrics_and_metadata.csv\")\n",
    "    print(\"Query saved to local csv file.\")\n",
    " \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/deepfunding/.venv/lib/python3.13/site-packages/google/cloud/bigquery/table.py:1820: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query saved to local csv file.\n"
     ]
    }
   ],
   "source": [
    "df_repo = get_repo_metrics_and_metadata(repo_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dependent_repos_in_OSO():\n",
    "  query = \"\"\"\n",
    "  select\n",
    "    p.project_id,\n",
    "    pkgs.package_artifact_source,\n",
    "    pkgs.package_artifact_name,\n",
    "    count(distinct sboms.from_project_id) as num_dependents\n",
    "  from `oso_production.package_owners_v0` pkgs\n",
    "  join `oso_production.sboms_v0` sboms\n",
    "    on pkgs.package_artifact_name = sboms.to_package_artifact_name\n",
    "    and pkgs.package_artifact_source = sboms.to_package_artifact_source\n",
    "  join `oso_production.projects_v1` p\n",
    "    on pkgs.package_owner_project_id = p.project_id\n",
    "  where pkgs.package_owner_project_id is not null\n",
    "  group by 1,2,3\n",
    "  order by 4 desc\n",
    "  \"\"\"\n",
    "\n",
    "  results = client.query(query)\n",
    "  df = results.to_dataframe()\n",
    "  df.to_csv(f\"{raw_path}/dependent-metrics.csv\")\n",
    "  print(\"Query saved to local csv file.\")\n",
    "  \n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/deepfunding/.venv/lib/python3.13/site-packages/google/cloud/bigquery/table.py:1820: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query saved to local csv file.\n"
     ]
    }
   ],
   "source": [
    "df_dependent = get_dependent_repos_in_OSO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
