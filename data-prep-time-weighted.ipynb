{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "part_path = Path(\"part-2\")\n",
    "part_path.mkdir(exist_ok=True)\n",
    "\n",
    "raw_path = Path(f\"{part_path}/raw\")\n",
    "raw_path.mkdir(exist_ok=True)\n",
    "\n",
    "processed_path = Path(f\"{part_path}/processed\")\n",
    "processed_path.mkdir(exist_ok=True)\n",
    "\n",
    "submission_path = Path(f\"{part_path}/submission\")\n",
    "submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_array(arr):\n",
    "    return \"'\" + \"','\".join(arr) + \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_str(projects):\n",
    "    projects = [p.replace('https://github.com/', '') for p in projects]\n",
    "    return projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_str_df(df):\n",
    "    df['project_a'] = df['project_a'].str.replace('https://github.com/', '')\n",
    "    df['project_b'] = df['project_b'].str.replace('https://github.com/', '')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    if str(part_path) == 'part-1':\n",
    "        # repository_url = (\n",
    "        #     \"https://raw.githubusercontent.com/deepfunding/mini-contest/refs/heads/main/\"\n",
    "        # )\n",
    "        \n",
    "        # df_train = pd.read_csv(f\"{repository_url}/dataset.csv\")\n",
    "        # df_test = pd.read_csv(f\"{repository_url}/test.csv\")\n",
    "        # df_train.to_csv(f\"{part_path}/train.csv\", index=False)\n",
    "        # df_test.to_csv(f\"{part_path}/test.csv\", index=False)\n",
    "        df_train = pd.read_csv(f\"{part_path}/train.csv\")\n",
    "        df_test = pd.read_csv(f\"{part_path}/test.csv\")\n",
    "        \n",
    "    elif str(part_path) == 'part-2':\n",
    "        df_train = pd.read_csv(f\"{part_path}/train.csv\")\n",
    "        df_test = pd.read_csv(f\"{part_path}/test.csv\")\n",
    "     \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = pd.concat([\n",
    "    df_train['project_a'],\n",
    "    df_train['project_b'],\n",
    "    df_test['project_a'],\n",
    "    df_test['project_b']\n",
    "]).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/mochajs/mocha',\n",
       " 'https://github.com/chzyer/readline',\n",
       " 'https://github.com/gulpjs/gulp',\n",
       " 'https://github.com/webpack/webpack',\n",
       " 'https://github.com/redux-saga/redux-saga']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimed_projects = remove_str(projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2016-04', '2016-07', '2016-10', '2017-01', '2017-04', '2017-07',\n",
       "       '2017-10', '2018-01', '2018-04', '2018-07', '2018-10', '2019-01',\n",
       "       '2019-04', '2019-07', '2019-10', '2020-01', '2020-04', '2020-07',\n",
       "       '2020-10', '2021-01', '2021-04', '2021-07', '2021-10', '2022-01',\n",
       "       '2022-04', '2022-07', '2022-10', '2023-01', '2023-04', '2023-07',\n",
       "       '2023-10'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.quarter.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2024-01', '2024-04', '2024-07', '2024-10'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.quarter.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f\"{processed_path}/train-pre-embeddings.csv\")\n",
    "df_test = pd.read_csv(f\"{processed_path}/test-pre-embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter mappings:\n",
      "2016-04: 0.5000\n",
      "2016-07: 0.5147\n",
      "2016-10: 0.5294\n",
      "2017-01: 0.5441\n",
      "2017-04: 0.5588\n",
      "2017-07: 0.5735\n",
      "2017-10: 0.5882\n",
      "2018-01: 0.6029\n",
      "2018-04: 0.6176\n",
      "2018-07: 0.6324\n",
      "2018-10: 0.6471\n",
      "2019-01: 0.6618\n",
      "2019-04: 0.6765\n",
      "2019-07: 0.6912\n",
      "2019-10: 0.7059\n",
      "2020-01: 0.7206\n",
      "2020-04: 0.7353\n",
      "2020-07: 0.7500\n",
      "2020-10: 0.7647\n",
      "2021-01: 0.7794\n",
      "2021-04: 0.7941\n",
      "2021-07: 0.8088\n",
      "2021-10: 0.8235\n",
      "2022-01: 0.8382\n",
      "2022-04: 0.8529\n",
      "2022-07: 0.8676\n",
      "2022-10: 0.8824\n",
      "2023-01: 0.8971\n",
      "2023-04: 0.9118\n",
      "2023-07: 0.9265\n",
      "2023-10: 0.9412\n",
      "2024-01: 0.9559\n",
      "2024-04: 0.9706\n",
      "2024-07: 0.9853\n",
      "2024-10: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Create quarter to index mapping\n",
    "quarters = df_train.quarter.unique().tolist() + df_test.quarter.unique().tolist()\n",
    "quarters.sort()  # Sort chronologically\n",
    "quarter_to_index = {quarter: idx for idx, quarter in enumerate(quarters, 1)}\n",
    "\n",
    "# Calculate weights as before\n",
    "indices = np.arange(1, 36)\n",
    "weights = 0.5 + ((indices - 1) / 34) * 0.5\n",
    "weights_list = weights.tolist()\n",
    "\n",
    "# Create quarter to weight mapping\n",
    "quarter_to_weight = {quarter: weights_list[idx-1] for quarter, idx in quarter_to_index.items()}\n",
    "\n",
    "# Example usage:\n",
    "print(\"Quarter mappings:\")\n",
    "for quarter, weight in quarter_to_weight.items():\n",
    "    print(f\"{quarter}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = [\n",
    "   \"size\", \n",
    "   \"size_b\", \n",
    "   \"size_ratio\",\n",
    "   \"stars\", \n",
    "   \"stars_b\", \n",
    "   \"stars_ratio\",\n",
    "   \"watchers\",\n",
    "   \"watchers_b\",\n",
    "   \"watchers_ratio\",\n",
    "   \"forks\", \n",
    "   \"forks_b\", \n",
    "   \"forks_ratio\", \n",
    "   \"open_issues\", \n",
    "   \"open_issues_b\", \n",
    "   \"issues_ratio\",\n",
    "   \"subscribers_count\", \n",
    "   \"subscribers_count_b\",  \n",
    "   \"subscribers_ratio\",\n",
    "   \"commit_code\",\n",
    "   \"commit_code_b\",\n",
    "   \"commits_ratio\",\n",
    "   \"forked\",\n",
    "   \"forked_b\",\n",
    "   \"forked_ratio\",\n",
    "   \"issue_closed\",\n",
    "   \"issue_closed_b\",\n",
    "   \"issue_closed_ratio\",\n",
    "   \"issue_comment\",\n",
    "   \"issue_comment_b\",\n",
    "   \"issue_comment_ratio\",\n",
    "   \"issue_opened\",\n",
    "   \"issue_opened_b\",\n",
    "   \"issue_opened_ratio\",\n",
    "   \"issue_reopened\",\n",
    "   \"issue_reopened_b\",\n",
    "   \"issue_reopened_ratio\",\n",
    "   \"pull_request_closed\",\n",
    "   \"pull_request_closed_b\",\n",
    "   \"pull_request_closed_ratio\",\n",
    "   \"pull_request_merged\",\n",
    "   \"pull_request_merged_b\",\n",
    "   \"pull_request_merged_ratio\",\n",
    "   \"pull_request_opened\",\n",
    "   \"pull_request_opened_b\",\n",
    "   \"pull_request_opened_ratio\",\n",
    "   \"pull_request_reopened\",\n",
    "   \"pull_request_reopened_b\",\n",
    "   \"pull_request_reopened_ratio\",\n",
    "   \"pull_request_review_comment\",\n",
    "   \"pull_request_review_comment_b\",\n",
    "   \"pull_request_review_comment_ratio\",\n",
    "   \"release_published\",\n",
    "   \"release_published_b\",\n",
    "   \"release_published_ratio\",\n",
    "   \"starred\",\n",
    "   \"starred_b\",\n",
    "   \"starred_ratio\",\n",
    "   \"v_index\",\n",
    "   \"v_index_b\",\n",
    "   \"v_index_ratio\",\n",
    "   \"stars_intersection_v_index\",\n",
    "   \"stars_b_intersection_v_index_b\",\n",
    "   \"stars_ratio_intersection_v_index_ratio\",\n",
    "   \"num_dependents\",\n",
    "   \"num_dependents_b\",\n",
    "   \"dependency_rank\",\n",
    "   \"dependency_rank_b\",\n",
    "   \"num_dependents_ratio\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of weighted features:\n",
      "   quarter         stars       stars_b\n",
      "0  2016-04  11349.500000   1054.500000\n",
      "1  2016-04  11349.500000  16531.000000\n",
      "2  2016-04   1054.500000  16531.000000\n",
      "3  2016-07   1085.514706  17017.205882\n",
      "4  2016-07   1085.514706  11683.308824\n"
     ]
    }
   ],
   "source": [
    "# Get the weights for each row based on quarter\n",
    "weights = df_train['quarter'].map(quarter_to_weight)\n",
    "\n",
    "# Apply weights to features\n",
    "for base in base_features:\n",
    "    # Weight features ending in _a\n",
    "    df_train[f'{base}'] = df_train[f'{base}'] * weights\n",
    "    \n",
    "# Do the same for test data\n",
    "weights_test = df_test['quarter'].map(quarter_to_weight)\n",
    "for base in base_features:\n",
    "    df_test[f'{base}'] = df_test[f'{base}'] * weights_test\n",
    "    \n",
    "# Display example to verify\n",
    "print(\"Sample of weighted features:\")\n",
    "sample_cols = ['quarter', 'stars', 'stars_b']\n",
    "print(df_train[sample_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(f\"{processed_path}/train-weighted.csv\")\n",
    "df_test.to_csv(f\"{processed_path}/test-weighted.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
