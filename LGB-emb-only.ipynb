{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_path = Path(\"part-1\")\n",
    "part_path.mkdir(exist_ok=True)\n",
    "\n",
    "raw_path = Path(f\"{part_path}/raw\")\n",
    "raw_path.mkdir(exist_ok=True)\n",
    "\n",
    "processed_path = Path(f\"{part_path}/processed\")\n",
    "processed_path.mkdir(exist_ok=True)\n",
    "\n",
    "submission_path = Path(f\"{part_path}/submission\")\n",
    "submission_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f\"{processed_path}/train-embeddings-only.csv\")\n",
    "df_test = pd.read_csv(f\"{processed_path}/test-embeddings-only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>project_a</th>\n",
       "      <th>project_b</th>\n",
       "      <th>weight_a</th>\n",
       "      <th>weight_b</th>\n",
       "      <th>overview</th>\n",
       "      <th>embedding</th>\n",
       "      <th>overview_b</th>\n",
       "      <th>embedding_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>3410</td>\n",
       "      <td>https://github.com/erigontech/erigon</td>\n",
       "      <td>https://github.com/bluealloy/revm</td>\n",
       "      <td>0.514138</td>\n",
       "      <td>0.485862</td>\n",
       "      <td>**Overview of Erigon**\\n\\n1. **By Function or ...</td>\n",
       "      <td>[0.018576037138700485, 0.011656154878437519, 0...</td>\n",
       "      <td>Certainly! Here's an overview of the \"revm\" pr...</td>\n",
       "      <td>[0.011202394030988216, 0.06186612322926521, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                             project_a  \\\n",
       "2386  3410  https://github.com/erigontech/erigon   \n",
       "\n",
       "                              project_b  weight_a  weight_b  \\\n",
       "2386  https://github.com/bluealloy/revm  0.514138  0.485862   \n",
       "\n",
       "                                               overview  \\\n",
       "2386  **Overview of Erigon**\\n\\n1. **By Function or ...   \n",
       "\n",
       "                                              embedding  \\\n",
       "2386  [0.018576037138700485, 0.011656154878437519, 0...   \n",
       "\n",
       "                                             overview_b  \\\n",
       "2386  Certainly! Here's an overview of the \"revm\" pr...   \n",
       "\n",
       "                                            embedding_b  \n",
       "2386  [0.011202394030988216, 0.06186612322926521, 0....  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(literal_eval(df_train.loc[0, \"embedding\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "def normalize_l2(x):\n",
    "    x = np.array(x)\n",
    "    if x.ndim == 1:\n",
    "        norm = np.linalg.norm(x)\n",
    "        if norm == 0:\n",
    "            return x\n",
    "        return x / norm\n",
    "    else:\n",
    "        norm = np.linalg.norm(x, 2, axis=1, keepdims=True)\n",
    "        return np.where(norm == 0, x, x / norm)\n",
    "    \n",
    "def process_embeddings(embedding_series):\n",
    "    return np.array([normalize_l2(literal_eval(emb)[:512]) for emb in embedding_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_a = process_embeddings(df_train.embedding)\n",
    "embeddings_b = process_embeddings(df_train.embedding_b)\n",
    "train_features = np.hstack([\n",
    "    embeddings_a,\n",
    "    embeddings_b\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_a = process_embeddings(df_test.embedding)\n",
    "embeddings_b = process_embeddings(df_test.embedding_b)\n",
    "test_features = np.hstack([\n",
    "    embeddings_a,\n",
    "    embeddings_b\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_features\n",
    "y = df_train[\"weight_a\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 107363\n",
      "[LightGBM] [Info] Number of data points in the train set: 1909, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score 0.547007\n",
      "[LightGBM] [Info] Total Bins 105542\n",
      "[LightGBM] [Info] Number of data points in the train set: 1909, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score 0.550762\n",
      "[LightGBM] [Info] Total Bins 105837\n",
      "[LightGBM] [Info] Number of data points in the train set: 1910, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score 0.542937\n",
      "[LightGBM] [Info] Total Bins 108199\n",
      "[LightGBM] [Info] Number of data points in the train set: 1910, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score 0.546384\n",
      "[LightGBM] [Info] Total Bins 107452\n",
      "[LightGBM] [Info] Number of data points in the train set: 1910, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score 0.542994\n",
      "Cross-validation MSE: 0.0171 (+/- 0.0017)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "lgb_train_data = lgb.Dataset(X, label=y)\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"mse\",\n",
    "    \"force_col_wise\": True,\n",
    "    \"num_leaves\": 60,\n",
    "    # \"min_data_in_leaf\": 20,  # Helps prevent overfitting\n",
    "    # \"max_bin\": 255,  # Reduces complexity\n",
    "    # \"learning_rate\": 0.01,  # Smaller learning rate for better control\n",
    "    # \"min_gain_to_split\": 0.1,  # Prevents unnecessary splits\n",
    "    # \"lambda_l1\": 0.1,  # L1 regularization\n",
    "    # \"lambda_l2\": 0.1,  # L2 regularization\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    # Create training and validation datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params, \n",
    "        train_data, \n",
    "        valid_sets=[val_data],\n",
    "        # num_boost_round=1000,\n",
    "        # early_stopping_rounds=50,\n",
    "        # verbose_eval=False\n",
    "    )\n",
    "\n",
    "    # Make predictions and calculate MSE\n",
    "    y_pred = model.predict(X_val)\n",
    "    mse = np.mean((y_val - y_pred) ** 2)\n",
    "    cv_scores.append(mse)\n",
    "\n",
    "# Calculate mean and std of MSE scores\n",
    "cv_scores = np.array(cv_scores)\n",
    "mean_mse = cv_scores.mean()\n",
    "std_mse = cv_scores.std()\n",
    "\n",
    "print(f\"Cross-validation MSE: {mean_mse:.4f} (+/- {std_mse:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 110105\n",
      "[LightGBM] [Info] Number of data points in the train set: 2387, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score 0.546016\n"
     ]
    }
   ],
   "source": [
    "# Train model on the entire dataset\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_features\n",
    "\n",
    "lgb_test_data = lgb.Dataset(X_test)\n",
    "\n",
    "test_predictions = model.predict(X_test)\n",
    "test_predictions = pd.Series(test_predictions.tolist()).round(6).clip(0.000001, 0.999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All predictions are < 1\n"
     ]
    }
   ],
   "source": [
    "# Check if any predictions are >= 1\n",
    "if (test_predictions >= 1).any():\n",
    "    print(\"Warning: Found predictions >= 1\")\n",
    "    print(\"Max prediction value:\", test_predictions.max())\n",
    "else:\n",
    "    print(\"All predictions are < 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importance = model.feature_importance()\n",
    "\n",
    "# Create DataFrame in Pandas\n",
    "feature_importance = pd.DataFrame({\"feature\": test_features, \"importance\": importance.tolist()})\n",
    "\n",
    "# Sort by importance in ascending order\n",
    "feature_importance = feature_importance.sort_values(by=\"importance\", ascending=True)\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(12, 8))  # Adjust width and height as needed\n",
    "\n",
    "# Plot horizontal bar chart\n",
    "feature_importance.plot.barh(x=\"feature\", y=\"importance\", legend=False, figsize=(12, 10))\n",
    "\n",
    "# Improve layout\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: part-2/submission/submission_2025-02-08_18-17-16-mse_0.038278.csv\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "submission_path = Path(f\"{part_path}/submission\")\n",
    "\n",
    "df_submission = df_test[[\"id\"]].copy()  # Select \"id\" column\n",
    "df_submission[\"pred\"] = test_predictions  # Add predictions column\n",
    "\n",
    "# Create filename with timestamp and MSE\n",
    "filename = f\"{submission_path}/submission_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}-mse_{mean_mse:.6f}.csv\"\n",
    "\n",
    "# Save to CSV\n",
    "df_submission.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Saved file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# import lightgbm as lgb\n",
    "\n",
    "# # Define the parameter grid\n",
    "# param_grid = {\n",
    "#     'num_leaves': [31, 50, 100],\n",
    "#     'max_depth': [-1, 5, 10],  # -1 means no limit\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'min_child_samples': [20, 50, 100],\n",
    "#     'subsample': [0.8, 0.9, 1.0],\n",
    "#     'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "#     'reg_alpha': [0, 0.1, 0.5],\n",
    "#     'reg_lambda': [0, 0.1, 0.5]\n",
    "# }\n",
    "# param_grid_small = {\n",
    "#     'num_leaves': [31, 50],\n",
    "#     'learning_rate': [0.01, 0.1],\n",
    "#     'n_estimators': [100, 200],\n",
    "#     'subsample': [0.8, 1.0]\n",
    "# }\n",
    "\n",
    "# # Initialize LightGBM model\n",
    "# lgb_model = lgb.LGBMRegressor(\n",
    "#     objective='regression',\n",
    "#     metric='mse',\n",
    "#     force_col_wise=True,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Initialize GridSearchCV\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=lgb_model,\n",
    "#     param_grid=param_grid_small,\n",
    "#     cv=5,\n",
    "#     scoring='neg_mean_squared_error',\n",
    "#     n_jobs=-1,  # Use all CPU cores\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # Perform grid search\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# # Print results\n",
    "# print(\"\\nBest parameters found:\")\n",
    "# print(grid_search.best_params_)\n",
    "# print(f\"\\nBest MSE: {-grid_search.best_score_:.4f}\")\n",
    "\n",
    "# # Get the best model\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# # Make predictions on test set using best model\n",
    "# X_test = df_test[features].to_numpy()\n",
    "# test_predictions = best_model.predict(X_test)\n",
    "# test_predictions = pd.Series(test_predictions).round(6).clip(0)\n",
    "\n",
    "# # Save feature importance plot for best model\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# feature_importance = pd.DataFrame({\n",
    "#     'feature': features,\n",
    "#     'importance': best_model.feature_importances_\n",
    "# })\n",
    "# feature_importance = feature_importance.sort_values('importance', ascending=True)\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# feature_importance.plot.barh(x='feature', y='importance', legend=False)\n",
    "# plt.xlabel('Importance')\n",
    "# plt.ylabel('Feature')\n",
    "# plt.title('Feature Importance (Best Model)')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
